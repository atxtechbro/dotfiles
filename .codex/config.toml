# OpenAI Codex Configuration
# This file uses TOML format as required by Codex CLI
# Documentation: https://github.com/openai/codex/blob/main/codex-rs/config.md

# Default model configuration
# Model is specified via command line alias (-m gpt-5)
temperature = 0.7
max_tokens = 8192  # Match Claude Code's max output tokens for fair comparison

# Sandbox and permissions
sandbox = "local"
autonomy = "medium"
interactive = false

# Authentication (subscription-based)
# Use 'codex login' to authenticate with ChatGPT Plus/Pro/Team subscription

# Logging configuration
log_level = "info"
log_file = "~/.codex/logs/codex.log"

# MCP Server configurations
# Note: Codex uses 'mcp_servers' (underscore) not 'mcpServers' (camelCase)

[mcp_servers.playwright]
command = "npx"
args = ["@playwright/mcp@latest"]
env = { FASTMCP_LOG_LEVEL = "ERROR" }

# Additional MCP servers can be added here
# Example format:
# [mcp_servers.github]
# command = "npx"
# args = ["-y", "@modelcontextprotocol/server-github"]
# env = { GITHUB_TOKEN = "$GITHUB_TOKEN" }

## Note: no fallback_models here — rely on Codex's own defaults/selection.

# Integration settings
[integrations]
git_enabled = true
git_auto_commit = false

# Permissions configuration
[permissions]
allow = ["read", "write", "execute", "mcp"]
deny = ["network:external", "system:critical"]

# Use ChatGPT subscription-based auth (no API keys)
preferred_auth_method = "chatgpt"

# -----------------------------------------------------------------------------
# Model providers and profiles (per Codex docs)
# Docs: https://github.com/openai/codex/blob/main/docs/config.md
# -----------------------------------------------------------------------------

# Minimal profile for GPT‑4o (uses built-in OpenAI provider defaults)
# Invoke with: codex --profile gpt4o "..."

[profiles.gpt4o]
model = "gpt-4o"
