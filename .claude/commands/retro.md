Conduct a collaborative retrospective on our recent work in this session.

## Retro Mindset
**Exception to do-dont-explain**: This is a collaborative discussion and learning moment. Be consultative, reflective, and thorough. Take time to think through decisions, tensions, and alternatives.

## Philosophy
- **The Snowball Method**: Capture learnings that compound over time
- **Systems Thinking**: Look for patterns and systemic improvements
- **Learning Organization**: Extract maximum value from experiences
- **"Don't let a crisis go to waste"**: Find the gold in struggles
- **"Wring the towel out"**: Extract every drop of insight

## Process
1. **Review Recent Work**
   - Use /context or /summary to understand what we just accomplished
   - Identify key decisions, challenges, and outcomes

2. **Collaborative Discussion**
   - What patterns emerged?
   - Where did we struggle or need course corrections?
   - What "aha moments" occurred?
   - Which approaches felt natural vs forced?

3. **Extract Insights**
# Post-PR Mini Retro

After submitting a pull request for feature-related workflows, conduct a mini retro focused on systems improvement. This supports the Snowball Method by capturing learnings and dedicating 20% of time to systems improvement.

## Retro Questions

**What worked well?**
- Which documented procedures were followed successfully?
- What felt smooth and efficient in the workflow?

**What didn't work as expected?**
- Which procedures were unclear or incomplete?
- Where did manual course corrections become necessary?
- What assumptions or approaches needed adjustment?

**Procedure adherence:**
- Which defined procedures were used as documented?
- Which procedures were improvised or done with uncertainty?
- Where did the human need to steer or provide manual input?

**Systems improvement opportunities:**
- What procedures need updating or clarification?
- What new procedures should be documented?
- What tools or workflows could be enhanced?

**Formatting overhead check:**
- Did any requirements feel like unnecessary cognitive load or "formatting overhead"?
- Were there moments where precision requirements (line counts, exact formatting, etc.) made tasks harder than needed?
- What formatting or precision requirements could be relaxed to reduce friction?
- Permission to flag when working harder/longer than necessary due to overly specific constraints

**Tool boundary clarity:**
- Were there moments of uncertainty about which tool to use for a task?
- Which tool descriptions or boundaries could be clearer?
- Which tools needed example usage, edge cases, or input format requirements to be more obvious?
- What tool definitions felt like they needed "prompt engineering attention" to be clearer?

**Principle tensions:**
- Which principles came into tension during decision points?
- Which principle did you lean on when there was conflict, and why?
- How did choosing one principle over another create tension or trade-offs?
- What decisions required balancing competing principles?

This retro helps identify the 20% of systems work that enables the 80% of feature work to flow more smoothly.


4. **Systems Improvements**
   - What procedures need updating?
   - What new patterns should we document?
   - Which principles guided our decisions?
   - What would make future work smoother?

5. **Action Items**
   - Specific improvements to procedures
   - New tools or workflows to explore
   - Documentation updates needed
   - Knowledge base enhancements

## Output Format
Structure as a back-and-forth discussion that allows insights to emerge naturally. Plan the discussion topics before diving in. Focus on creating a learning dialogue that benefits both human and AI understanding.

Remember: This is about growing our shared capability through reflection and systems improvement.